{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib.request import urlretrieve\n",
    "from memory_profiler import memory_usage\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Download the data from figshare to local computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\yxiong\\\\DSCI_525_group21\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yxiong\\DSCI_525_group21\\notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/yxiong/DSCI_525_group21/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14096681  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figshare/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_link_only': False,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'id': 26579150,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'size': 58863},\n",
       " {'is_link_only': False,\n",
       "  'name': 'environment.yml',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'id': 26579171,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'size': 192},\n",
       " {'is_link_only': False,\n",
       "  'name': 'README.md',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'id': 26586554,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'size': 5422},\n",
       " {'is_link_only': False,\n",
       "  'name': 'data.zip',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'id': 26766812,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'size': 814041183},\n",
       " {'is_link_only': False,\n",
       "  'name': 'get_data.py',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'id': 26766815,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'size': 4113}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files\n",
    "# the file we target for is the 4th file with .zip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files_to_dl = [\"data.zip\"]  # feel free to add other files here\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Combining CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.50</td>\n",
       "      <td>3.293256e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.50</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.50</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.50</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-36.25</td>\n",
       "      <td>-35.00</td>\n",
       "      <td>140.625</td>\n",
       "      <td>142.50</td>\n",
       "      <td>1.047658e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932835</th>\n",
       "      <td>2014-12-27 12:00:00</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>-28.75</td>\n",
       "      <td>151.875</td>\n",
       "      <td>153.75</td>\n",
       "      <td>2.951144e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932836</th>\n",
       "      <td>2014-12-28 12:00:00</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>-28.75</td>\n",
       "      <td>151.875</td>\n",
       "      <td>153.75</td>\n",
       "      <td>2.257118e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932837</th>\n",
       "      <td>2014-12-29 12:00:00</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>-28.75</td>\n",
       "      <td>151.875</td>\n",
       "      <td>153.75</td>\n",
       "      <td>1.204670e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932838</th>\n",
       "      <td>2014-12-30 12:00:00</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>-28.75</td>\n",
       "      <td>151.875</td>\n",
       "      <td>153.75</td>\n",
       "      <td>2.632404e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932839</th>\n",
       "      <td>2014-12-31 12:00:00</td>\n",
       "      <td>-30.00</td>\n",
       "      <td>-28.75</td>\n",
       "      <td>151.875</td>\n",
       "      <td>153.75</td>\n",
       "      <td>3.431610e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1932840 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  lat_min  lat_max  lon_min  lon_max  \\\n",
       "0        1889-01-01 12:00:00   -36.25   -35.00  140.625   142.50   \n",
       "1        1889-01-02 12:00:00   -36.25   -35.00  140.625   142.50   \n",
       "2        1889-01-03 12:00:00   -36.25   -35.00  140.625   142.50   \n",
       "3        1889-01-04 12:00:00   -36.25   -35.00  140.625   142.50   \n",
       "4        1889-01-05 12:00:00   -36.25   -35.00  140.625   142.50   \n",
       "...                      ...      ...      ...      ...      ...   \n",
       "1932835  2014-12-27 12:00:00   -30.00   -28.75  151.875   153.75   \n",
       "1932836  2014-12-28 12:00:00   -30.00   -28.75  151.875   153.75   \n",
       "1932837  2014-12-29 12:00:00   -30.00   -28.75  151.875   153.75   \n",
       "1932838  2014-12-30 12:00:00   -30.00   -28.75  151.875   153.75   \n",
       "1932839  2014-12-31 12:00:00   -30.00   -28.75  151.875   153.75   \n",
       "\n",
       "         rain (mm/day)  \n",
       "0         3.293256e-13  \n",
       "1         0.000000e+00  \n",
       "2         0.000000e+00  \n",
       "3         0.000000e+00  \n",
       "4         1.047658e-02  \n",
       "...                ...  \n",
       "1932835   2.951144e-02  \n",
       "1932836   2.257118e-01  \n",
       "1932837   1.204670e-01  \n",
       "1932838   2.632404e-02  \n",
       "1932839   3.431610e-02  \n",
       "\n",
       "[1932840 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### just listing to get an idea how individual file looks like \n",
    "use_cols = [\"time\",'lat_min','lat_max','lon_min', 'lon_max', 'rain (mm/day)']\n",
    "df = pd.read_csv(\"./figshare/ACCESS-CM2_daily_rainfall_NSW.csv\", usecols=use_cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3499.92 MiB, increment: 0.04 MiB\n",
      "Processing the file ACCESS-CM2_daily_rainfall_NSW.csv\n",
      "Processing the file ACCESS-ESM1-5_daily_rainfall_NSW.csv\n",
      "Processing the file AWI-ESM-1-1-LR_daily_rainfall_NSW.csv\n",
      "Processing the file BCC-CSM2-MR_daily_rainfall_NSW.csv\n",
      "Processing the file BCC-ESM1_daily_rainfall_NSW.csv\n",
      "Processing the file CanESM5_daily_rainfall_NSW.csv\n",
      "Processing the file CMCC-CM2-HR4_daily_rainfall_NSW.csv\n",
      "Processing the file CMCC-CM2-SR5_daily_rainfall_NSW.csv\n",
      "Processing the file CMCC-ESM2_daily_rainfall_NSW.csv\n",
      "Processing the file EC-Earth3-Veg-LR_daily_rainfall_NSW.csv\n",
      "Processing the file FGOALS-f3-L_daily_rainfall_NSW.csv\n",
      "Processing the file FGOALS-g3_daily_rainfall_NSW.csv\n",
      "Processing the file GFDL-CM4_daily_rainfall_NSW.csv\n",
      "Processing the file GFDL-ESM4_daily_rainfall_NSW.csv\n",
      "Processing the file INM-CM4-8_daily_rainfall_NSW.csv\n",
      "Processing the file INM-CM5-0_daily_rainfall_NSW.csv\n",
      "Processing the file KIOST-ESM_daily_rainfall_NSW.csv\n",
      "Processing the file MIROC6_daily_rainfall_NSW.csv\n",
      "Processing the file MPI-ESM-1-2-HAM_daily_rainfall_NSW.csv\n",
      "Processing the file MPI-ESM1-2-HR_daily_rainfall_NSW.csv\n",
      "Processing the file MPI-ESM1-2-LR_daily_rainfall_NSW.csv\n",
      "Processing the file MRI-ESM2-0_daily_rainfall_NSW.csv\n",
      "Processing the file NESM3_daily_rainfall_NSW.csv\n",
      "Processing the file NorESM2-LM_daily_rainfall_NSW.csv\n",
      "Processing the file NorESM2-MM_daily_rainfall_NSW.csv\n",
      "Processing the file SAM0-UNICON_daily_rainfall_NSW.csv\n",
      "Processing the file TaiESM1_daily_rainfall_NSW.csv\n",
      "Wall time: 31min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "# Shows time that regular python takes to merge file\n",
    "# Join all data together\n",
    "import pandas as pd\n",
    "use_cols = [\"time\",'lat_min','lat_max','lon_min', 'lon_max', 'rain (mm/day)']\n",
    "\n",
    "files = glob.glob('./figshare/*.csv')\n",
    "\n",
    "df_all = None\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    if '_daily_rainfall_NSW.csv' in filename:\n",
    "        print(f\"Processing the file {filename}\")\n",
    "        model = filename.split('_daily_rainfall_NSW.csv')[0]\n",
    "\n",
    "        df = pd.read_csv(file, usecols=use_cols, index_col=0)\n",
    "        df['model'] = model    \n",
    "\n",
    "        if df_all is None:\n",
    "            df_all = df\n",
    "        else:\n",
    "            df_all = df_all.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('./figshare/combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7G\tfigshare/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh figshare/combined_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation: \n",
    "#### Computer: IntelI5, 8GB Ram. Wall time 31 min. peak memory: 3499.92 MiB, increment: 0.04 MiB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load combined CSV in memory and perform simple EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the file ACCESS-CM2_daily_rainfall_NSW.csv\n",
      "Processing the file ACCESS-ESM1-5_daily_rainfall_NSW.csv\n",
      "Processing the file AWI-ESM-1-1-LR_daily_rainfall_NSW.csv\n",
      "Processing the file BCC-CSM2-MR_daily_rainfall_NSW.csv\n",
      "Processing the file BCC-ESM1_daily_rainfall_NSW.csv\n",
      "Processing the file CanESM5_daily_rainfall_NSW.csv\n",
      "Processing the file CMCC-CM2-HR4_daily_rainfall_NSW.csv\n",
      "Processing the file CMCC-CM2-SR5_daily_rainfall_NSW.csv\n",
      "Processing the file CMCC-ESM2_daily_rainfall_NSW.csv\n",
      "Processing the file EC-Earth3-Veg-LR_daily_rainfall_NSW.csv\n",
      "Processing the file FGOALS-f3-L_daily_rainfall_NSW.csv\n",
      "Processing the file FGOALS-g3_daily_rainfall_NSW.csv\n",
      "Processing the file GFDL-CM4_daily_rainfall_NSW.csv\n",
      "Processing the file GFDL-ESM4_daily_rainfall_NSW.csv\n",
      "Processing the file INM-CM4-8_daily_rainfall_NSW.csv\n",
      "Processing the file INM-CM5-0_daily_rainfall_NSW.csv\n",
      "Processing the file KIOST-ESM_daily_rainfall_NSW.csv\n",
      "Processing the file MIROC6_daily_rainfall_NSW.csv\n",
      "Processing the file MPI-ESM-1-2-HAM_daily_rainfall_NSW.csv\n",
      "Processing the file MPI-ESM1-2-HR_daily_rainfall_NSW.csv\n",
      "Processing the file MPI-ESM1-2-LR_daily_rainfall_NSW.csv\n",
      "Processing the file MRI-ESM2-0_daily_rainfall_NSW.csv\n",
      "Processing the file NESM3_daily_rainfall_NSW.csv\n",
      "Processing the file NorESM2-LM_daily_rainfall_NSW.csv\n",
      "Processing the file NorESM2-MM_daily_rainfall_NSW.csv\n",
      "Processing the file SAM0-UNICON_daily_rainfall_NSW.csv\n",
      "Processing the file TaiESM1_daily_rainfall_NSW.csv\n",
      "peak memory: 102.23 MiB, increment: 6.07 MiB\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "use_cols = [\"time\",'lat_min','lat_max','lon_min', 'lon_max', 'rain (mm/day)']\n",
    "\n",
    "files = glob.glob('./figshare/*.csv')\n",
    "\n",
    "ddf_all = None\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    if '_daily_rainfall_NSW.csv' in filename:\n",
    "        print(f\"Processing the file {filename}\")\n",
    "        model = filename.split('_daily_rainfall_NSW.csv')[0]\n",
    "\n",
    "        ddf = dd.read_csv(file, assume_missing=True, usecols=use_cols)\n",
    "        ddf['model'] = model    \n",
    "\n",
    "        if ddf_all is None:\n",
    "            ddf_all = ddf\n",
    "        else:\n",
    "            ddf_all = ddf_all.append(ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation: \n",
    "#### Computer: IntelI5, 8GB Ram. Using Dask, now the Wall time 9s. peak memory: 249.95 MiB, increment: 7.42 MiB. This is way way faster than using Pandas to load the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some basic EDA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "    int64\n",
       "      ...\n",
       "Name: model, dtype: int64\n",
       "Dask Name: value-counts-agg, 25 tasks"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time              object\n",
       "lat_min          float64\n",
       "lat_max          float64\n",
       "lon_min          float64\n",
       "lon_max          float64\n",
       "rain (mm/day)    float64\n",
       "model             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>5.727971e-17</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>-4.460195e-18</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>2.592095e-02</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1889-01-06 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>4.662255e+00</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1889-01-07 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>3.083404e-08</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1889-01-08 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>1.055728e-04</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1889-01-09 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>1.616503e-04</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1889-01-10 12:00:00</td>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>1.176145e-04</td>\n",
       "      <td>TaiESM1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min   lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "0  1889-01-01 12:00:00 -35.811518 -34.86911  140.625  141.875   5.727971e-17   \n",
       "1  1889-01-02 12:00:00 -35.811518 -34.86911  140.625  141.875  -4.460195e-18   \n",
       "2  1889-01-03 12:00:00 -35.811518 -34.86911  140.625  141.875   0.000000e+00   \n",
       "3  1889-01-04 12:00:00 -35.811518 -34.86911  140.625  141.875   0.000000e+00   \n",
       "4  1889-01-05 12:00:00 -35.811518 -34.86911  140.625  141.875   2.592095e-02   \n",
       "5  1889-01-06 12:00:00 -35.811518 -34.86911  140.625  141.875   4.662255e+00   \n",
       "6  1889-01-07 12:00:00 -35.811518 -34.86911  140.625  141.875   3.083404e-08   \n",
       "7  1889-01-08 12:00:00 -35.811518 -34.86911  140.625  141.875   1.055728e-04   \n",
       "8  1889-01-09 12:00:00 -35.811518 -34.86911  140.625  141.875   1.616503e-04   \n",
       "9  1889-01-10 12:00:00 -35.811518 -34.86911  140.625  141.875   1.176145e-04   \n",
       "\n",
       "     model  \n",
       "0  TaiESM1  \n",
       "1  TaiESM1  \n",
       "2  TaiESM1  \n",
       "3  TaiESM1  \n",
       "4  TaiESM1  \n",
       "5  TaiESM1  \n",
       "6  TaiESM1  \n",
       "7  TaiESM1  \n",
       "8  TaiESM1  \n",
       "9  TaiESM1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Perform EDA in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
