{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1 - Group 21\n",
    "\n",
    "https://github.com/UBC-MDS/DSCI_525_group21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "#import intake\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import xarray as xr\n",
    "from urllib.request import urlretrieve\n",
    "#import proplot as pplot\n",
    "#from joblib import Parallel, delayed\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")  # ignore some annoying matplotlib warnings\n",
    "from memory_profiler import memory_usage\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more library loading\n",
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14096681  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figshare/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata output\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # \n",
    "files = data[\"files\"] # we only want the data and readme 'name' key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.5 s, sys: 4.64 s, total: 10.1 s\n",
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#download readme and data.zip files only\n",
    "files_to_dl = [\"README.md\", \"data.zip\"]\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 s, sys: 2.75 s, total: 18.8 s\n",
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#extract zip files to repo\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Combining data CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 155.11 MiB, increment: 0.21 MiB\n",
      "Processing the file AWI-ESM-1-1-LR_daily_rainfall_NSW.csv\n",
      "Processing the file MIROC6_daily_rainfall_NSW.csv\n",
      "Processing the file FGOALS-f3-L_daily_rainfall_NSW.csv\n",
      "Processing the file NorESM2-MM_daily_rainfall_NSW.csv\n",
      "Processing the file EC-Earth3-Veg-LR_daily_rainfall_NSW.csv\n",
      "Processing the file CanESM5_daily_rainfall_NSW.csv\n",
      "Processing the file NESM3_daily_rainfall_NSW.csv\n",
      "Processing the file GFDL-ESM4_daily_rainfall_NSW.csv\n",
      "Processing the file MPI-ESM-1-2-HAM_daily_rainfall_NSW.csv\n",
      "Processing the file ACCESS-CM2_daily_rainfall_NSW.csv\n",
      "Processing the file FGOALS-g3_daily_rainfall_NSW.csv\n",
      "Processing the file INM-CM5-0_daily_rainfall_NSW.csv\n",
      "Processing the file MRI-ESM2-0_daily_rainfall_NSW.csv\n",
      "Processing the file MPI-ESM1-2-HR_daily_rainfall_NSW.csv\n",
      "Processing the file SAM0-UNICON_daily_rainfall_NSW.csv\n",
      "Processing the file NorESM2-LM_daily_rainfall_NSW.csv\n",
      "Processing the file BCC-CSM2-MR_daily_rainfall_NSW.csv\n",
      "Processing the file TaiESM1_daily_rainfall_NSW.csv\n",
      "Processing the file KIOST-ESM_daily_rainfall_NSW.csv\n",
      "Processing the file MPI-ESM1-2-LR_daily_rainfall_NSW.csv\n",
      "Processing the file CMCC-CM2-HR4_daily_rainfall_NSW.csv\n",
      "Processing the file CMCC-ESM2_daily_rainfall_NSW.csv\n",
      "Processing the file CMCC-CM2-SR5_daily_rainfall_NSW.csv\n",
      "Processing the file GFDL-CM4_daily_rainfall_NSW.csv\n",
      "Processing the file BCC-ESM1_daily_rainfall_NSW.csv\n",
      "Processing the file ACCESS-ESM1-5_daily_rainfall_NSW.csv\n",
      "Processing the file INM-CM4-8_daily_rainfall_NSW.csv\n",
      "CPU times: user 1min 13s, sys: 11.2 s, total: 1min 24s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "# Shows time that regular python takes to merge file\n",
    "# Join all data together\n",
    "import pandas as pd\n",
    "use_cols = [\"time\",'lat_min','lat_max','lon_min', 'lon_max', 'rain (mm/day)']\n",
    "\n",
    "files = glob.glob('./figshare/*.csv')\n",
    "df_all = None\n",
    "\n",
    "for file in files:\n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    if '_daily_rainfall_NSW.csv' in filename:\n",
    "        print(f\"Processing the file {filename}\")\n",
    "        model = filename.split('_daily_rainfall_NSW.csv')[0]\n",
    "\n",
    "        df = pd.read_csv(file, usecols=use_cols, index_col=0)\n",
    "        df['model'] = model    \n",
    "\n",
    "        if df_all is None:\n",
    "            df_all = df\n",
    "        else:\n",
    "            df_all = df_all.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save combined file\n",
    "df_all.to_csv('./figshare/combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6G\tfigshare/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "#get file size of combined csv\n",
    "du -sh figshare/combined_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "Our team members had the following computer specs:  \n",
    "\n",
    "| Team Member       | Ram     | Processor     |\n",
    "| :------------- | :----------: | -----------: |\n",
    "|  Cal | 16GB   | AMD Ryzen 5 3600 6-core    |\n",
    "| Justin  | 32GB  | Intel i5 | \n",
    "| Anita   |  12GB | Intel i5  | \n",
    "| Yuan  |  8GB | Intel i5  | \n",
    "\n",
    "Below are our processing times and peak memory usage by team member: \n",
    "\n",
    "| Team Member       |  Processing Time     | Peak Memory Usage |\n",
    "| :------------- | :---------- | :-----------: |\n",
    "|  Cal |  1min 13sec  | 137 mb |\n",
    "|  Justin |  1min 24sec  | 155 mb |\n",
    "|  Anita |  3min 34sec  | 9050 mb |\n",
    "|  Yuan |  9sec (using Dash)  | 250 mb |\n",
    "\n",
    "We also used the Pandas default writing method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load the combined CSV to memory and perform a simple EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance using Default Pandas Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "NorESM2-MM          3541230\n",
      "TaiESM1             3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "FGOALS-f3-L         3219300\n",
      "MRI-ESM2-0          3037320\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "FGOALS-g3           1287720\n",
      "KIOST-ESM           1287720\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "CanESM5              551880\n",
      "BCC-ESM1             551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 12154.78 MiB, increment: 8446.80 MiB\n",
      "CPU times: user 51.3 s, sys: 3.97 s, total: 55.3 s\n",
      "Wall time: 55.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# time to read/calculate when using default Pandas method\n",
    "df = pd.read_csv(\"figshare/combined_data.csv\")\n",
    "print(df[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance when loading in Select Columns only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "NorESM2-MM          3541230\n",
      "TaiESM1             3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "FGOALS-f3-L         3219300\n",
      "MRI-ESM2-0          3037320\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "FGOALS-g3           1287720\n",
      "KIOST-ESM           1287720\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "CanESM5              551880\n",
      "BCC-ESM1             551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 13288.14 MiB, increment: 4633.28 MiB\n",
      "CPU times: user 42.7 s, sys: 3.74 s, total: 46.5 s\n",
      "Wall time: 46.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "use_cols = [\"time\", \"rain (mm/day)\", \"model\"]\n",
    "df = pd.read_csv(\"figshare/combined_data.csv\", usecols = use_cols)\n",
    "print(df[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance when reading file using chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int64\n",
      "peak memory: 8988.77 MiB, increment: 2193.34 MiB\n",
      "CPU times: user 53.2 s, sys: 3.42 s, total: 56.6 s\n",
      "Wall time: 56.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# 10 million chunk size\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"figshare/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int64\n",
      "peak memory: 7117.98 MiB, increment: 99.35 MiB\n",
      "CPU times: user 57.2 s, sys: 1.45 s, total: 58.7 s\n",
      "Wall time: 58.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# 1 million chunk size\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"figshare/combined_data.csv\", chunksize=1_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int64\n",
      "peak memory: 6945.82 MiB, increment: 31.89 MiB\n",
      "CPU times: user 56 s, sys: 1.06 s, total: 57.1 s\n",
      "Wall time: 57.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"figshare/combined_data.csv\", chunksize=500_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance when loading with simplier data types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time              object\n",
       "rain (mm/day)    float64\n",
       "model             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "NorESM2-MM          3541230\n",
      "TaiESM1             3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "FGOALS-f3-L         3219300\n",
      "MRI-ESM2-0          3037320\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "FGOALS-g3           1287720\n",
      "KIOST-ESM           1287720\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "CanESM5              551880\n",
      "BCC-ESM1             551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 12867.46 MiB, increment: 5923.33 MiB\n",
      "CPU times: user 54.1 s, sys: 3.74 s, total: 57.9 s\n",
      "Wall time: 58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "col_type = {'time':object, 'lat_min':np.float32, 'lat_max':np.float32, 'lon_min': np.float32, \n",
    "           'lon_max': np.float32, 'rain (mm/day)': np.float32, 'model': object}\n",
    "df2 = pd.read_csv(\"figshare/combined_data.csv\", dtype=col_type)\n",
    "print(df2[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time              object\n",
       "lat_min          float32\n",
       "lat_max          float32\n",
       "lon_min          float32\n",
       "lon_max          float32\n",
       "rain (mm/day)    float32\n",
       "model             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Dask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 20956.89 MiB, increment: 677.56 MiB\n",
      "CPU times: user 1min 21s, sys: 6.85 s, total: 1min 28s\n",
      "Wall time: 33.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# time to read/calculate when using default Dask method\n",
    "d_df = dd.read_csv(\"figshare/combined_data.csv\")\n",
    "result = d_df.model.value_counts().compute()\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*observations*\n",
    "\n",
    "For part 5, we tasked each of our team members to investigate each one of the approaches. Please see the summary of results below which were performed on Justin's machine (i5 processor (4 core, 8 threads), 32GB memory).\n",
    "\n",
    "* Default Pandas approach\n",
    "* Changing the Data Type of the columns using float32 instead of float64 for 4 out of 7 columns\n",
    "* Reading in fewer columns (date, rain and model)\n",
    "* Reading in using several chunk sizes (0.5M, 1M and 10M chunks)\n",
    "* Loading with Dask\n",
    "\n",
    "| Approach Taken       |  Processing Time     | Peak Memory Usage |  Increment Memory Usage |\n",
    "| :------------- | :---------- | :----------- | :-----------: |\n",
    "|  Default Pandas | 55s  | 12,155 MB | 8,447 MB |\n",
    "| Change Data Type | 58s   |  12,867 MB  | 5,923 MB   |\n",
    "|  Fewer Columns |  47s  | 13,288 MB | 463 MB |\n",
    "|  Loading in 0.5 M chunk size|  57s  | 8,989 MB | 2,193 MB |\n",
    "|  Loading in 1 M chunk size|  59s  | 7,118 MB | 99 MB |\n",
    "|  Loading in 10 M chunk size|  57s  | 6,946 MB | 32 MB |\n",
    "|  Dask |  1m 28s  | 20,957 MB | 677MB |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The fastest approach appears to be using fewer columns and the slowest approach was Dask. There are probably more advanced tuning in Dask to improve this but we only used the default settings.\n",
    "\n",
    "Note that:\n",
    "* **Peak memory**: peak memory usage of your system (including memory usage of other processes) during the program runtime.\n",
    "* **Increment**: the increment in memory usage relative to the memory usage just before the program is run \n",
    "\n",
    "The lowest peak memory usage is using chunking with 10M chunk size and the highest peak memory usage is using the default Dask.\n",
    "\n",
    "The lowest increment memory usage is using chunking with 10M chunk size and the highest peak memory usage is using the default Pandas approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "## install the packages https://arrow.apache.org/docs/python/install.html\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "## How to install put instructions https://anaconda.org/conda-forge/rpy2\n",
    "import rpy2.rinterface\n",
    "# install this https://pypi.org/project/rpy2-arrow/#description  pip install rpy2-arrow\n",
    "# have to install this as well conda install -c conda-forge r-arrow \n",
    "import rpy2_arrow.pyarrow_rarrow as pyra\n",
    "### instruction\n",
    "import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "#just seeing if its available\n",
    "library(\"arrow\")\n",
    "library(\"dplyr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 14884.18 MiB, increment: 4126.20 MiB\n",
      "CPU times: user 23.5 s, sys: 2.52 s, total: 26 s\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "## read more on the datasets here  https://arrow.apache.org/docs/python/dataset.html\n",
    "dataset = ds.dataset(\"figshare/combined_data.csv\", format=\"csv\")\n",
    "## this is of arrow table format\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# experiment in writing in feather format \n",
    "#feather.write_feather(table, 'figshare/figshare.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "\u001b[90m# A tibble: 27 x 2\u001b[39m\n",
      "   model                  n\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m ACCESS-CM2       1\u001b[4m9\u001b[24m\u001b[4m3\u001b[24m\u001b[4m2\u001b[24m840\n",
      "\u001b[90m 2\u001b[39m ACCESS-ESM1-5    1\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m\u001b[4m0\u001b[24m700\n",
      "\u001b[90m 3\u001b[39m AWI-ESM-1-1-LR    \u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m6\u001b[24m420\n",
      "\u001b[90m 4\u001b[39m BCC-CSM2-MR      3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m5\u001b[24m340\n",
      "\u001b[90m 5\u001b[39m BCC-ESM1          \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 6\u001b[39m CanESM5           \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 7\u001b[39m CMCC-CM2-HR4     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 8\u001b[39m CMCC-CM2-SR5     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 9\u001b[39m CMCC-ESM2        3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m10\u001b[39m EC-Earth3-Veg-LR 3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m7\u001b[24m320\n",
      "\u001b[90m# … with 17 more rows\u001b[39m\n",
      "Time difference of 8.571577 secs\n",
      "CPU times: user 7.56 s, sys: 5.71 s, total: 13.3 s\n",
      "Wall time: 8.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "### her we are showing how much time it took to read a feather file what we wrote in python\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"figshare/figshare.feather\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why I chose Feather?\n",
    "\n",
    "We chose the feather data format - which was designed to improve data interoperability (ex. language agnostic - R and Python) while dealing with columnar tabular data. I also wanted the fastest load and save times. Feather is a fast, lightweight, and easy-to-use binary file format. Feather also doesn't use compression internally and works best with SSD drives.\n",
    "\n",
    "However, if I needed to store this for long term storage, I would not use Feather because the file format is relatively new and can change. Feather does not guarantee if the format will stay the same between versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
