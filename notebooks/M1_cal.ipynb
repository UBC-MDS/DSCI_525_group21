{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "#import intake\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import xarray as xr\n",
    "from urllib.request import urlretrieve\n",
    "#import proplot as pplot\n",
    "#from joblib import Parallel, delayed\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")  # ignore some annoying matplotlib warnings\n",
    "from memory_profiler import memory_usage\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schaf\\miniconda3\\envs\\525\\lib\\site-packages\\rpy2\\robjects\\packages.py:366: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# more library loading\n",
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary metadata\n",
    "article_id = 14096681  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figshare/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata output\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # \n",
    "files = data[\"files\"] # we only want the data and readme 'name' key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#download readme and data.zip files only\n",
    "files_to_dl = [\"README.md\", \"data.zip\"]\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#extract zip files to repo\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Combining data CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 137.07 MiB, increment: 0.23 MiB\n",
      "Processing the file ACCESS-CM2_daily_rainfall_NSW.csv\n",
      "Processing the file ACCESS-ESM1-5_daily_rainfall_NSW.csv\n",
      "Processing the file AWI-ESM-1-1-LR_daily_rainfall_NSW.csv\n",
      "Processing the file BCC-CSM2-MR_daily_rainfall_NSW.csv\n",
      "Processing the file BCC-ESM1_daily_rainfall_NSW.csv\n",
      "Processing the file CanESM5_daily_rainfall_NSW.csv\n",
      "Processing the file CMCC-CM2-HR4_daily_rainfall_NSW.csv\n",
      "Processing the file CMCC-CM2-SR5_daily_rainfall_NSW.csv\n",
      "Processing the file CMCC-ESM2_daily_rainfall_NSW.csv\n",
      "Processing the file EC-Earth3-Veg-LR_daily_rainfall_NSW.csv\n",
      "Processing the file FGOALS-f3-L_daily_rainfall_NSW.csv\n",
      "Processing the file FGOALS-g3_daily_rainfall_NSW.csv\n",
      "Processing the file GFDL-CM4_daily_rainfall_NSW.csv\n",
      "Processing the file GFDL-ESM4_daily_rainfall_NSW.csv\n",
      "Processing the file INM-CM4-8_daily_rainfall_NSW.csv\n",
      "Processing the file INM-CM5-0_daily_rainfall_NSW.csv\n",
      "Processing the file KIOST-ESM_daily_rainfall_NSW.csv\n",
      "Processing the file MIROC6_daily_rainfall_NSW.csv\n",
      "Processing the file MPI-ESM-1-2-HAM_daily_rainfall_NSW.csv\n",
      "Processing the file MPI-ESM1-2-HR_daily_rainfall_NSW.csv\n",
      "Processing the file MPI-ESM1-2-LR_daily_rainfall_NSW.csv\n",
      "Processing the file MRI-ESM2-0_daily_rainfall_NSW.csv\n",
      "Processing the file NESM3_daily_rainfall_NSW.csv\n",
      "Processing the file NorESM2-LM_daily_rainfall_NSW.csv\n",
      "Processing the file NorESM2-MM_daily_rainfall_NSW.csv\n",
      "Processing the file SAM0-UNICON_daily_rainfall_NSW.csv\n",
      "Processing the file TaiESM1_daily_rainfall_NSW.csv\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%memit\n",
    "\n",
    "# Shows time that regular python takes to merge file\n",
    "# Join all data together\n",
    "import pandas as pd\n",
    "use_cols = [\"time\",'lat_min','lat_max','lon_min', 'lon_max', 'rain (mm/day)']\n",
    "\n",
    "files = glob.glob('./figshare/*.csv')\n",
    "df_all = None\n",
    "\n",
    "for file in files:\n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    if '_daily_rainfall_NSW.csv' in filename:\n",
    "        print(f\"Processing the file {filename}\")\n",
    "        model = filename.split('_daily_rainfall_NSW.csv')[0]\n",
    "\n",
    "        df = pd.read_csv(file, usecols=use_cols, index_col=0)\n",
    "        df['model'] = model    \n",
    "\n",
    "        if df_all is None:\n",
    "            df_all = df\n",
    "        else:\n",
    "            df_all = df_all.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save combined file\n",
    "df_all.to_csv('./figshare/combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7G\tfigshare/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "#get file size of combined csv\n",
    "du -sh figshare/combined_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "Our team members had the following computer specs:  \n",
    "\n",
    "| Team Member       | Ram     | Processor     |\n",
    "| :------------- | :----------: | -----------: |\n",
    "|  Cal | 16GB   | AMD Ryzen 5 3600 6-core    |\n",
    "| Justin  | 32GB  | Intel i5 | \n",
    "| Anita   |  x |x  | \n",
    "| Yuan  |  x |x  | \n",
    "\n",
    "We used the Pandas default writing method, and found the processing times and peak memory usage to vary by member as: \n",
    "\n",
    "| Team Member       |  Processing Time     | Peak Memory Usage |\n",
    "| :------------- | :---------- | :-----------: |\n",
    "|  Cal |  1min 13sec  | 137 mb |\n",
    "|  Justin |  1min 07sec  | 1593 mb |\n",
    "|  Anita |  xmin xsec  | x mb |\n",
    "|  Yuan |  xmin xsec  | x mb |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load the combined CSV to memory and perform a simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "CMCC-ESM2           3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "TaiESM1             3541230\n",
      "SAM0-UNICON         3541153\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "FGOALS-f3-L         3219300\n",
      "MRI-ESM2-0          3037320\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 11281.64 MiB, increment: 7587.66 MiB\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df = pd.read_csv(\"figshare/combined_data.csv\")\n",
    "print(df[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "CMCC-ESM2           3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "TaiESM1             3541230\n",
      "SAM0-UNICON         3541153\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "FGOALS-f3-L         3219300\n",
      "MRI-ESM2-0          3037320\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 11356.05 MiB, increment: 4572.77 MiB\n",
      "Wall time: 51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "use_cols = [\"time\", \"rain (mm/day)\", \"model\"]\n",
    "df = pd.read_csv(\"figshare/combined_data.csv\", usecols = use_cols)\n",
    "print(df[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*observations*\n",
    "\n",
    "By loading in only 3 out of the original 7 columns our combined CSV, we obtained the following results: \n",
    "- peak memory was not improved: 11.36 GB (reduced columns) versus 11.28 GB (all columns)\n",
    "- memory incremental usage was cut in half: 4.6 GB (reduced columns) versus 7.6 GB (all columns)\n",
    "- processing run time was moderately improved: 53.1 seconds (reduced columns) versus 1min 11 seconds (all columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "## install the packages https://arrow.apache.org/docs/python/install.html\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "## How to install put instructions https://anaconda.org/conda-forge/rpy2\n",
    "import rpy2.rinterface\n",
    "# install this https://pypi.org/project/rpy2-arrow/#description  pip install rpy2-arrow\n",
    "# have to install this as well conda install -c conda-forge r-arrow \n",
    "import rpy2_arrow.pyarrow_rarrow as pyra\n",
    "### instruction\n",
    "import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "#just seeing if its available\n",
    "library(\"arrow\")\n",
    "library(\"dplyr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4137.67 MiB, increment: 3874.96 MiB\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "## read more on the datasets here  https://arrow.apache.org/docs/python/dataset.html\n",
    "dataset = ds.dataset(\"figshare/combined_data.csv\", format=\"csv\")\n",
    "## this is of arrow table format\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1224] Failed to open local file 'figshare/feather'. Detail: [Windows error 1224] The requested operation cannot be performed on a file with a user-mapped section open.\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\525\\lib\\site-packages\\pyarrow\\feather.py\u001b[0m in \u001b[0;36mwrite_feather\u001b[1;34m(df, dest, compression, compression_level, chunksize, version)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         ext.write_feather(table, dest, compression=compression,\n\u001b[0m\u001b[0;32m    183\u001b[0m                           \u001b[0mcompression_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression_level\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                           chunksize=chunksize, version=version)\n",
      "\u001b[1;32m~\\miniconda3\\envs\\525\\lib\\site-packages\\pyarrow\\feather.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.write_feather\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\525\\lib\\site-packages\\pyarrow\\io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.get_writer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\525\\lib\\site-packages\\pyarrow\\io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.OSFile.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\525\\lib\\site-packages\\pyarrow\\io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.OSFile._open_writable\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\525\\lib\\site-packages\\pyarrow\\error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\525\\lib\\site-packages\\pyarrow\\error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1224] Failed to open local file 'figshare/feather'. Detail: [Windows error 1224] The requested operation cannot be performed on a file with a user-mapped section open.\r\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# experiment in writing in feather format \n",
    "feather.write_feather(table, 'figshare/feather')\n",
    "# note that this won't work on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "### her we are showing how much time it took to read a feather file what we wrote in python\n",
    "# note this won't work given the problem in the last code chunk\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"figshare/feather\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**observation**\n",
    "\n",
    "The following table shows how the reading in, and performing of simple EDA (i.e., getting the number of observations per model) varied based on our team members and using default Pandas versus using Feather for R:\n",
    "\n",
    "| Team Member       | Processing Time (Feather vs Pandas)  | Peak Memory Usage (Feather vs Pandas)  |\n",
    "| :------------- | :----------: | -----------: |\n",
    "|  Cal |  x  | x    |\n",
    "| Justin  | x  | x | \n",
    "| Anita   |  x |x  | \n",
    "| Yuan  |  x |x  | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
